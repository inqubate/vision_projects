{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST Convolutional Neural network Capstone Project\n",
    "            Saurav Bakshi (Team 4)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**\n",
    "\n",
    "Implement a simple CNN with the following parameters fixed.Â \n",
    "A Convolutional layer will have 32 neurons (feature maps) and a 5x5 feature detector.\n",
    "\n",
    "**Key hyperparameters**\n",
    "1. Learning Rate = 0.01\n",
    "2. Activation = **Sigmoid** for Neural Network layers and **Softmax** for output layer\n",
    "3. Optimizer = Stochastic Gradient Descent (SGD)\n",
    "4. Epochs = 5\n",
    "5. Batch Size = 128\n",
    "6. Metrics = Accuracy\n",
    "7. Loss Function = Categorical Cross Entropy\n",
    "\n",
    "Assumption - The dataset will be split into Train, Validation and Test. However for the task 1, validation data will not be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis 1 - The CNNs model should still result in a high accuracy even with basic hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as python_random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "np.random.seed(123)\n",
    "python_random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from mlxtend.evaluate import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Capture and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading MNIST...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Reading MNIST...\")\n",
    "((train_images, train_labels), (testX, testY)) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_types = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to the range of [0, 1]\n",
    "train_images = train_images.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample out validation data from trainX\n",
    "(trainX, valX, trainY, valY) = train_test_split(train_images, train_labels,\n",
    "                                                test_size=0.2, stratify=train_labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data for input to the convolutional models\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "valX = valX.reshape((valX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28 , 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "valY = lb.transform(valY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_task1_model(activation, n_classes):\n",
    "    # Task 1\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = \"sigmoid\"\n",
    "learning_rate = 0.01\n",
    "opt = SGD(learning_rate)\n",
    "batch_size = 128\n",
    "n_epochs = 5\n",
    "n_classes = len(class_types)\n",
    "metrics = [\"accuracy\"]\n",
    "loss = \"categorical_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28, 1) (48000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape, trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 0s - loss: 2.5709 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.2566 - accuracy: 0.2223\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9729 - accuracy: 0.7176\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5588 - accuracy: 0.8353\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4682 - accuracy: 0.8606\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4223 - accuracy: 0.8765\n",
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 0s - loss: 2.5640 - accuracy: 0.1484WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.2349 - accuracy: 0.2232\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9192 - accuracy: 0.7297\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5470 - accuracy: 0.8391\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4623 - accuracy: 0.8618\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4187 - accuracy: 0.8770\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.0557 - accuracy: 0.2271\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9845 - accuracy: 0.7122\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5655 - accuracy: 0.8329\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4715 - accuracy: 0.8581\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4239 - accuracy: 0.8749\n",
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 0s - loss: 2.4548 - accuracy: 0.0859WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.8532 - accuracy: 0.2527\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8937 - accuracy: 0.7351\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5382 - accuracy: 0.8398\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4572 - accuracy: 0.8624\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4152 - accuracy: 0.8769\n",
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 0s - loss: 2.6831 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.1954 - accuracy: 0.2068\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9612 - accuracy: 0.7200\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5524 - accuracy: 0.8361\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.8613\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4186 - accuracy: 0.8766\n",
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 0s - loss: 2.5121 - accuracy: 0.1016WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.9306 - accuracy: 0.2471\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8771 - accuracy: 0.7388\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5407 - accuracy: 0.8410\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4594 - accuracy: 0.8623\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4171 - accuracy: 0.8777\n",
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 0s - loss: 2.3690 - accuracy: 0.1016WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.7399 - accuracy: 0.2542\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8608 - accuracy: 0.7425\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5339 - accuracy: 0.8421\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4556 - accuracy: 0.8629\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4143 - accuracy: 0.8779\n",
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 0s - loss: 2.6102 - accuracy: 0.0859WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.0797 - accuracy: 0.2495\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8967 - accuracy: 0.7345\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5406 - accuracy: 0.8402\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4580 - accuracy: 0.8631\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4154 - accuracy: 0.8780\n",
      "5.58 s Â± 119 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "t1_model = build_task1_model(activation, n_classes)\n",
    "t1_model.compile(loss=loss, optimizer=opt,\n",
    "            metrics=metrics)\n",
    "H = t1_model.fit(trainX, trainY,\n",
    "              epochs=n_epochs, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 0s - loss: 2.4327 - accuracy: 0.0859WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.7353 - accuracy: 0.2562\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8679 - accuracy: 0.7406\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5378 - accuracy: 0.8404\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4587 - accuracy: 0.8624\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4167 - accuracy: 0.8769\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                216330    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 216,650\n",
      "Trainable params: 216,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "t1_model = build_task1_model(activation, n_classes)\n",
    "t1_model.compile(loss=loss, optimizer=opt,\n",
    "            metrics=metrics)\n",
    "H = t1_model.fit(trainX, trainY,\n",
    "              epochs=n_epochs, batch_size=128)\n",
    "t1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy 0.8912\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "predictions = t1_model.predict(testX, batch_size=128)\n",
    "acc_score = accuracy_score(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1))\n",
    "print(f\"Model Accuracy {acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 Findings\n",
    "\n",
    "1. Model Accuracy is 89.12%\n",
    "2. The average time taken to train the model on a non-gpu PC is - 5.58s on MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "- Increase the complexity of the CNN by adding multiple convolution and dense layers.Â \n",
    "- Add one more convolutional layer with 32 neurons (feature maps) and a 5x5 feature detector.Â \n",
    "- Add a dense layer with 128 nodes.\n",
    "\n",
    "**Key hyperparameters**\n",
    "1. Learning Rate = 0.01\n",
    "2. Activation = **Sigmoid** for Neural Network layers and **Softmax** for output layer\n",
    "3. Optimizer = Stochastic Gradient Descent (SGD)\n",
    "4. Epochs = 5\n",
    "5. Batch Size = 128\n",
    "6. Metrics = Accuracy\n",
    "7. Loss Function = Categorical Cross Entropy\n",
    "\n",
    "Assumption - The dataset will be split into Train, Validation and Test. However for the task 1, validation data will not be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis 2 - When we increase the complexity of the Convolutional Neural Network, the time to train increases but the accuracy improves.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_task2_model(activation, n_classes):\n",
    "    # Task 2\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = \"sigmoid\"\n",
    "learning_rate = 0.01\n",
    "opt = SGD(learning_rate)\n",
    "batch_size = 128\n",
    "n_epochs = 5\n",
    "n_classes = len(class_types)\n",
    "metrics = [\"accuracy\"]\n",
    "loss = \"categorical_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_model = build_task2_model(activation, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_model.compile(loss=loss, optimizer=opt,\n",
    "            metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.3823 - accuracy: 0.9141WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0080s). Check your callbacks.\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3079 - accuracy: 0.9085\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3053 - accuracy: 0.9103\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3043 - accuracy: 0.9087\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3048 - accuracy: 0.9094\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3032 - accuracy: 0.9093\n",
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.3769 - accuracy: 0.9141WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0070s). Check your callbacks.\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3022 - accuracy: 0.9103\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2998 - accuracy: 0.9120\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2991 - accuracy: 0.9100\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2997 - accuracy: 0.9108\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2984 - accuracy: 0.9110\n",
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.3730 - accuracy: 0.9141WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0070s). Check your callbacks.\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2976 - accuracy: 0.9118\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2954 - accuracy: 0.9134\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2949 - accuracy: 0.9122\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2956 - accuracy: 0.9125\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2945 - accuracy: 0.9119\n",
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.3699 - accuracy: 0.9141WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0070s). Check your callbacks.\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2939 - accuracy: 0.9130\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2918 - accuracy: 0.9144\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2914 - accuracy: 0.9135\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2922 - accuracy: 0.9135\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2912 - accuracy: 0.9132\n",
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.3674 - accuracy: 0.9141WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0070s). Check your callbacks.\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2907 - accuracy: 0.9137\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2887 - accuracy: 0.9153\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2884 - accuracy: 0.9144\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2892 - accuracy: 0.9146\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2884 - accuracy: 0.9141\n",
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.3653 - accuracy: 0.9141WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0070s). Check your callbacks.\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2880 - accuracy: 0.9146\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2860 - accuracy: 0.9164\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2858 - accuracy: 0.9155\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2866 - accuracy: 0.9152\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2859 - accuracy: 0.9150\n",
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.3635 - accuracy: 0.9141WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0070s). Check your callbacks.\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2855 - accuracy: 0.9155\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2836 - accuracy: 0.9172\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2834 - accuracy: 0.9163\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2843 - accuracy: 0.9162\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2836 - accuracy: 0.9156\n",
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.3619 - accuracy: 0.9141WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0070s). Check your callbacks.\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2834 - accuracy: 0.9164\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2815 - accuracy: 0.9178\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2814 - accuracy: 0.9167\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2822 - accuracy: 0.9167\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2816 - accuracy: 0.9164\n",
      "16.4 s Â± 69.5 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "H = t2_model.fit(trainX, trainY,\n",
    "              epochs=n_epochs, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.3603 - accuracy: 0.9141WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0080s). Check your callbacks.\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2814 - accuracy: 0.9172\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2796 - accuracy: 0.9185\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2795 - accuracy: 0.9175\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2803 - accuracy: 0.9175\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2797 - accuracy: 0.9169\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 24, 24, 128)       4224      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                737290    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 751,082\n",
      "Trainable params: 751,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "H = t2_model.fit(trainX, trainY,\n",
    "              epochs=n_epochs, batch_size=128)\n",
    "t2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy 0.9226\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "predictions = t2_model.predict(testX, batch_size=128)\n",
    "acc_score = accuracy_score(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1))\n",
    "print(f\"Model Accuracy {acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 Findings\n",
    "\n",
    "1. Model Accuracy is 92.26% - This prove the hypothesis to be true as the prediction performance has slightly increased.\n",
    "2. The average time taken to train the model is - 16.4s on MNIST data which 3 times more than the Task 1 training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving the models built in Task 1 and Task 2\n",
    "**Hypothesis T3_H1 - Increasing number of epochs can increase accuracy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for Hypothesis T3_H1\n",
    "activation = \"sigmoid\"\n",
    "learning_rate = 0.01\n",
    "opt = SGD(learning_rate)\n",
    "batch_size = 128\n",
    "n_classes = len(class_types)\n",
    "metrics = [\"accuracy\"]\n",
    "loss = \"categorical_crossentropy\"\n",
    "# n_epochs = 5 initial number of epochs\n",
    "# all other hyperparameters remaining the same , number of epochs is increased to 10\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/375 [..............................] - ETA: 0s - loss: 0.4151 - accuracy: 0.9062WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3939 - accuracy: 0.8832\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3771 - accuracy: 0.8889\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3665 - accuracy: 0.8910\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3592 - accuracy: 0.8931\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3506 - accuracy: 0.8957\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3451 - accuracy: 0.8970\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3405 - accuracy: 0.8986\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3335 - accuracy: 0.9013\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.9022\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3258 - accuracy: 0.9044\n"
     ]
    }
   ],
   "source": [
    "# train the task 1 model\n",
    "H = t1_model.fit(trainX, trainY,\n",
    "              epochs=n_epochs, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy 0.913\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "predictions = t1_model.predict(testX, batch_size=128)\n",
    "acc_score = accuracy_score(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1))\n",
    "print(f\"Model Accuracy {acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.3589 - accuracy: 0.9141WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0070s). Check your callbacks.\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2796 - accuracy: 0.9178\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2778 - accuracy: 0.9192\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2777 - accuracy: 0.9179\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2786 - accuracy: 0.9181\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2780 - accuracy: 0.9177\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2774 - accuracy: 0.9180\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2777 - accuracy: 0.9181\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2762 - accuracy: 0.9183\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2768 - accuracy: 0.9189\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2758 - accuracy: 0.9185\n"
     ]
    }
   ],
   "source": [
    "# train the task 2 model\n",
    "H = t2_model.fit(trainX, trainY,\n",
    "              epochs=n_epochs, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy 0.9253\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "predictions = t2_model.predict(testX, batch_size=128)\n",
    "acc_score = accuracy_score(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1))\n",
    "print(f\"Model Accuracy {acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of epochs = 10\n",
    "\n",
    "Task 1 model Accuracy : 91.31%\n",
    "\n",
    "Task 2 model Accuracy : 92.53% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving the models built in Task 1 and Task 2\n",
    "**Hypothesis T3_H2 - Reducing the number of batches can increase accuracy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for Hypothesis T3_H1 - switching back the number of epochs to 5\n",
    "activation = \"sigmoid\"\n",
    "learning_rate = 0.01\n",
    "opt = SGD(learning_rate)\n",
    "batch_size = 128\n",
    "n_classes = len(class_types)\n",
    "metrics = [\"accuracy\"]\n",
    "loss = \"categorical_crossentropy\"\n",
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing the number of batches to 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3375 - accuracy: 0.8993\n",
      "Epoch 2/5\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3300 - accuracy: 0.9011\n",
      "Epoch 3/5\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.3237 - accuracy: 0.9039\n",
      "Epoch 4/5\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.3209 - accuracy: 0.9040\n",
      "Epoch 5/5\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.3180 - accuracy: 0.9050\n"
     ]
    }
   ],
   "source": [
    "# train the task 1 model\n",
    "\n",
    "H = t1_model.fit(trainX, trainY,\n",
    "              epochs=n_epochs, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy 0.9111\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "predictions = t1_model.predict(testX, batch_size=128)\n",
    "acc_score = accuracy_score(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1))\n",
    "print(f\"Model Accuracy {acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/750 [..............................] - ETA: 0s - loss: 0.4099 - accuracy: 0.9219WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0050s). Check your callbacks.\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.2879 - accuracy: 0.9151\n",
      "Epoch 2/5\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.2854 - accuracy: 0.9154\n",
      "Epoch 3/5\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.2833 - accuracy: 0.9159\n",
      "Epoch 4/5\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.2846 - accuracy: 0.9153\n",
      "Epoch 5/5\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.2842 - accuracy: 0.9150\n"
     ]
    }
   ],
   "source": [
    "# train the task 2 model\n",
    "\n",
    "H = t2_model.fit(trainX, trainY,\n",
    "              epochs=n_epochs, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy 0.9212\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "predictions = t2_model.predict(testX, batch_size=128)\n",
    "acc_score = accuracy_score(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1))\n",
    "print(f\"Model Accuracy {acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reducing the batch size also shows some improvement in the Accuracy of the model.**\n",
    "\n",
    "\n",
    "Task 1 model (Baseline) Accuracy - 89.15%\n",
    "Task 1 model Accuracy after reducing the batch size to 64 - 91.11%\n",
    "\n",
    "Task 2 model (Baseline) Accuracy - 91.58%\n",
    "Task 2 model Accuracy after reducing the batch size to 64 - 92.12%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2 - Using only convolutional layers will hyperparameter optimization have any impact help in increasing the accuracy?\n",
    "- Number of layers\n",
    "- Number of nodes\n",
    "- learning rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving the models built in Task 1 and Task 2\n",
    "**Hypothesis T3_H3 - Increasing the number of of layers can increase accuracy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_task3h3_model(activation, n_classes):\n",
    "    # Task 2\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation(activation))\n",
    "    #adding one more conv2d layer\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for Hypothesis T3_H3\n",
    "activation = \"sigmoid\"\n",
    "learning_rate = 0.01\n",
    "opt = SGD(learning_rate)\n",
    "batch_size = 128\n",
    "n_classes = len(class_types)\n",
    "metrics = [\"accuracy\"]\n",
    "loss = \"categorical_crossentropy\"\n",
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3h3_model = build_task3h3_model(activation, n_classes)\n",
    "t3h3_model.compile(loss=loss, optimizer=opt,\n",
    "            metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 2s - loss: 2.3514 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0080s). Check your callbacks.\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3292 - accuracy: 0.1010\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3236 - accuracy: 0.1037\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3214 - accuracy: 0.1034\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3215 - accuracy: 0.1021\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3188 - accuracy: 0.1041\n"
     ]
    }
   ],
   "source": [
    "# train the task 1 model\n",
    "\n",
    "H = t3h3_model.fit(trainX, trainY,\n",
    "              epochs=n_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy 0.0958\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "predictions = t3h3_model.predict(testX, batch_size=128)\n",
    "acc_score = accuracy_score(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1))\n",
    "print(f\"Model Accuracy {acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis T3H3 is not true.\n",
    "We can see that adding one more Conv2D layer has actually degraded the performances. It needs to be tested if adding a pooling layers would improve the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving the models built in Task 1 and Task 2\n",
    "**Hypothesis T3_H4 - Increasing the number of nodes in Conv2D can increase accuracy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_task3h4_model(activation, n_classes):\n",
    "    # Task 2\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "    model.add(Activation(activation))\n",
    "    #increasing the number of nodes to 64\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for Hypothesis T3_H4\n",
    "activation = \"sigmoid\"\n",
    "learning_rate = 0.01\n",
    "opt = SGD(learning_rate)\n",
    "batch_size = 128\n",
    "n_classes = len(class_types)\n",
    "metrics = [\"accuracy\"]\n",
    "loss = \"categorical_crossentropy\"\n",
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3h4_model = build_task3h4_model(activation, n_classes)\n",
    "t3h4_model.compile(loss=loss, optimizer=opt,\n",
    "            metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 0s - loss: 2.5269 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0100s). Check your callbacks.\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 5.4670 - accuracy: 0.1003\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3469 - accuracy: 0.1040\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3306 - accuracy: 0.1057\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3230 - accuracy: 0.1056\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3133 - accuracy: 0.1118\n"
     ]
    }
   ],
   "source": [
    "# train the task 3 model\n",
    "\n",
    "H = t3h4_model.fit(trainX, trainY,\n",
    "              epochs=n_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy 0.0958\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "predictions = t3h4_model.predict(testX, batch_size=128)\n",
    "acc_score = accuracy_score(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1))\n",
    "print(f\"Model Accuracy {acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis T3H4 is not true.\n",
    "We can see that adding more nodes to Conv2D layer has actually degraded the performance. It needs to be tested if adding a pooling layers would improve the accuracy or more epochs can improve the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving the models built in Task 1 and Task 2\n",
    "**Hypothesis T3_H5 - Increasing the number of nodes in Dense can increase accuracy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_task3h5_model(activation, n_classes):\n",
    "    # Task 2\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation(activation))\n",
    "    #increasing the number of nodes to 256\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for Hypothesis T3_H4\n",
    "activation = \"sigmoid\"\n",
    "learning_rate = 0.01\n",
    "opt = SGD(learning_rate)\n",
    "batch_size = 128\n",
    "n_classes = len(class_types)\n",
    "metrics = [\"accuracy\"]\n",
    "loss = \"categorical_crossentropy\"\n",
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3h5_model = build_task3h5_model(activation, n_classes)\n",
    "t3h5_model.compile(loss=loss, optimizer=opt,\n",
    "            metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 1s - loss: 2.5501 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0120s). Check your callbacks.\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 10.9484 - accuracy: 0.1008\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.4315 - accuracy: 0.1025\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.3835 - accuracy: 0.1018\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.3623 - accuracy: 0.1034\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.3460 - accuracy: 0.1040\n"
     ]
    }
   ],
   "source": [
    "H = t3h5_model.fit(trainX, trainY,\n",
    "              epochs=n_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy 0.0958\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "predictions = t3h5_model.predict(testX, batch_size=128)\n",
    "acc_score = accuracy_score(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1))\n",
    "print(f\"Model Accuracy {acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis T3H5 is not true.\n",
    "We can see that adding one more nodes to Dense layer has actually degraded the performances. It needs to be tested if adding a pooling layers would improve the accuracy or it may require more epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving the models built in Task 1 and Task 2\n",
    "**Hypothesis T3_H6 - Reducing the learning rate can improve accuracy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_task3h6_model(activation, n_classes):\n",
    "    # Task 2\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for Hypothesis T3_H4\n",
    "activation = \"sigmoid\"\n",
    "# reducing the learning rate to 0.001\n",
    "learning_rate = 0.001\n",
    "opt = SGD(learning_rate)\n",
    "batch_size = 128\n",
    "n_classes = len(class_types)\n",
    "metrics = [\"accuracy\"]\n",
    "loss = \"categorical_crossentropy\"\n",
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3h6_model = build_task3h6_model(activation, n_classes)\n",
    "t3h6_model.compile(loss=loss, optimizer=opt,\n",
    "            metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 2s - loss: 2.3685 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0070s). Check your callbacks.\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.5365 - accuracy: 0.1001\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.5113 - accuracy: 0.1015\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.5344 - accuracy: 0.0988\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.5368 - accuracy: 0.1014\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.5151 - accuracy: 0.1017\n"
     ]
    }
   ],
   "source": [
    "H = t3h6_model.fit(trainX, trainY,\n",
    "              epochs=n_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy 0.0958\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "predictions = t3h6_model.predict(testX, batch_size=128)\n",
    "acc_score = accuracy_score(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1))\n",
    "print(f\"Model Accuracy {acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis T3H6 is not true.\n",
    "We can see that reducing learning rate has actually degraded the performances. It needs to be tested if adding a pooling layers would improve the accuracy or it may require more epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving the models built in Task 1 and Task 2\n",
    "**Hypothesis T3_H7 - Increasing the learning rate can improve accuracy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_task3h7_model(activation, n_classes):\n",
    "    # Task 2\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for Hypothesis T3_H4\n",
    "activation = \"sigmoid\"\n",
    "# Increasing the learning rate to 0.1\n",
    "learning_rate = 0.1\n",
    "opt = SGD(learning_rate)\n",
    "batch_size = 128\n",
    "n_classes = len(class_types)\n",
    "metrics = [\"accuracy\"]\n",
    "loss = \"categorical_crossentropy\"\n",
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3h7_model = build_task3h7_model(activation, n_classes)\n",
    "t3h7_model.compile(loss=loss, optimizer=opt,\n",
    "            metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 2s - loss: 2.5798 - accuracy: 0.0234WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.0070s). Check your callbacks.\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 3.8096 - accuracy: 0.1038\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3014 - accuracy: 0.1124\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3014 - accuracy: 0.1124\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3014 - accuracy: 0.1121\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3014 - accuracy: 0.1124\n"
     ]
    }
   ],
   "source": [
    "H = t3h7_model.fit(trainX, trainY,\n",
    "              epochs=n_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy 0.1135\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "predictions = t3h7_model.predict(testX, batch_size=128)\n",
    "acc_score = accuracy_score(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1))\n",
    "print(f\"Model Accuracy {acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis T3H7 is not true.\n",
    "We can see that reducing learning rate has actually degraded the performances. It needs to be tested if adding a pooling layers would improve the accuracy or it may require more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

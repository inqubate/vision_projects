{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST Convolutional Neural network Capstone Project\n",
    "            Saurav Bakshi (Team 4)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**\n",
    "\n",
    "Implement a simple CNN with the following parameters fixed.Â \n",
    "A Convolutional layer will have 32 neurons (feature maps) and a 5x5 feature detector.\n",
    "\n",
    "**Key hyperparameters**\n",
    "1. Learning Rate = 0.01\n",
    "2. Activation = **Sigmoid** for Neural Network layers and **Softmax** for output layer\n",
    "3. Optimizer = Stochastic Gradient Descent (SGD)\n",
    "4. Epochs = 5\n",
    "5. Batch Size = 128\n",
    "6. Metrics = Accuracy\n",
    "7. Loss Function = Categorical Cross Entropy\n",
    "\n",
    "Assumption - The dataset will be split into Train, Validation and Test. However for the task 1, validation data will not be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis 1 - The CNNs model should still result in a high accuracy even with basic hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as python_random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "np.random.seed(123)\n",
    "python_random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from mlxtend.evaluate import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Capture and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading MNIST...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Reading MNIST...\")\n",
    "((train_images, train_labels), (testX, testY)) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_types = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to the range of [0, 1]\n",
    "train_images = train_images.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample out validation data from trainX\n",
    "(trainX, valX, trainY, valY) = train_test_split(train_images, train_labels,\n",
    "                                                test_size=0.2, stratify=train_labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data for input to the convolutional models\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "valX = valX.reshape((valX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28 , 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "valY = lb.transform(valY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_task1_model(activation, n_classes):\n",
    "    # Task 1\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = \"sigmoid\"\n",
    "learning_rate = 0.01\n",
    "opt = SGD(learning_rate)\n",
    "batch_size = 128\n",
    "n_epochs = 5\n",
    "n_classes = len(class_types)\n",
    "metrics = [\"accuracy\"]\n",
    "loss = \"categorical_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28, 1) (48000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape, trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 6.5475 - accuracy: 0.2729\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.8202 - accuracy: 0.7537\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5287 - accuracy: 0.8442\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4529 - accuracy: 0.8638\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4127 - accuracy: 0.8783\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 7.0146 - accuracy: 0.2265\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.9451 - accuracy: 0.7221\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5500 - accuracy: 0.8359\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4624 - accuracy: 0.8606\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.4179 - accuracy: 0.8761\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 6.8110 - accuracy: 0.2447\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.9020 - accuracy: 0.7344\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5457 - accuracy: 0.8381\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4612 - accuracy: 0.8619\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4178 - accuracy: 0.8766\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 7.0978 - accuracy: 0.2301\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.9308 - accuracy: 0.7261\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5478 - accuracy: 0.8379\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.4603 - accuracy: 0.8619\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4166 - accuracy: 0.8774\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 7.1471 - accuracy: 0.2342\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.8788 - accuracy: 0.7393\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5442 - accuracy: 0.8396\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4608 - accuracy: 0.8626\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4178 - accuracy: 0.8772\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 6.9858 - accuracy: 0.2447\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.8952 - accuracy: 0.7332\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5402 - accuracy: 0.8381\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4572 - accuracy: 0.8620\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4149 - accuracy: 0.8772\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 6.9920 - accuracy: 0.2417\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.8713 - accuracy: 0.7423\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5365 - accuracy: 0.8426\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4582 - accuracy: 0.8631\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4165 - accuracy: 0.8776\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 7.1717 - accuracy: 0.2174\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.9224 - accuracy: 0.7274\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5511 - accuracy: 0.8374\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4643 - accuracy: 0.8619\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4199 - accuracy: 0.8766\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 7.2311 - accuracy: 0.2340\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.9027 - accuracy: 0.7346\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5423 - accuracy: 0.8403\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4603 - accuracy: 0.8627\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4178 - accuracy: 0.8778\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 6.7777 - accuracy: 0.2454\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.9060 - accuracy: 0.7314\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5453 - accuracy: 0.8378\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.4611 - accuracy: 0.8612\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.4177 - accuracy: 0.8766\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 6.4021 - accuracy: 0.2714\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.8253 - accuracy: 0.7509\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5233 - accuracy: 0.8447\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.4503 - accuracy: 0.8648\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4110 - accuracy: 0.8782\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 6.3331 - accuracy: 0.2924\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.7883 - accuracy: 0.7638\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5200 - accuracy: 0.8452\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4491 - accuracy: 0.8650\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.4107 - accuracy: 0.8786\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 6.9672 - accuracy: 0.2414\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.9217 - accuracy: 0.7290\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5472 - accuracy: 0.8377\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4629 - accuracy: 0.8609\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4191 - accuracy: 0.8764\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 7.0327 - accuracy: 0.2308\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.9294 - accuracy: 0.7258\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5460 - accuracy: 0.8380\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4601 - accuracy: 0.8620\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4167 - accuracy: 0.8768\n",
      "30 s Â± 152 ms per loop (mean Â± std. dev. of 7 runs, 2 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "t1_model = build_task1_model(activation, n_classes)\n",
    "t1_model.compile(loss=loss, optimizer=opt,\n",
    "            metrics=metrics)\n",
    "H = t1_model.fit(trainX, trainY,\n",
    "              epochs=n_epochs, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                216330    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 216,650\n",
      "Trainable params: 216,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "t1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy 0.8913\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "predictions = model.predict(testX, batch_size=128)\n",
    "acc_score = accuracy_score(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1))\n",
    "print(f\"Model Accuracy {acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 Findings\n",
    "\n",
    "1. Model Accuracy is 89.13%\n",
    "2. The average time taken to train the model on a non-gpu PC is - 30s on MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "- Increase the complexity of the CNN by adding multiple convolution and dense layers.Â \n",
    "- Add one more convolutional layer with 32 neurons (feature maps) and a 5x5 feature detector.Â \n",
    "- Add a dense layer with 128 nodes.\n",
    "\n",
    "**Key hyperparameters**\n",
    "1. Learning Rate = 0.01\n",
    "2. Activation = **Sigmoid** for Neural Network layers and **Softmax** for output layer\n",
    "3. Optimizer = Stochastic Gradient Descent (SGD)\n",
    "4. Epochs = 5\n",
    "5. Batch Size = 128\n",
    "6. Metrics = Accuracy\n",
    "7. Loss Function = Categorical Cross Entropy\n",
    "\n",
    "Assumption - The dataset will be split into Train, Validation and Test. However for the task 1, validation data will not be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis 2 - When we increase the complexity of the Convolutional Neural Network, the time to train increases but the accuracy improves.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_task2_model(activation, n_classes):\n",
    "    # Task 2\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = \"sigmoid\"\n",
    "learning_rate = 0.01\n",
    "opt = SGD(learning_rate)\n",
    "batch_size = 128\n",
    "n_epochs = 5\n",
    "n_classes = len(class_types)\n",
    "metrics = [\"accuracy\"]\n",
    "loss = \"categorical_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_model = build_task2_model(activation, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_model.compile(loss=loss, optimizer=opt,\n",
    "            metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "375/375 [==============================] - 47s 126ms/step - loss: 7.0537 - accuracy: 0.1006\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 45s 121ms/step - loss: 2.3735 - accuracy: 0.1032\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 44s 119ms/step - loss: 2.3491 - accuracy: 0.1015\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 44s 118ms/step - loss: 2.3389 - accuracy: 0.1026\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 44s 117ms/step - loss: 2.3296 - accuracy: 0.1033\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 44s 117ms/step - loss: 2.3265 - accuracy: 0.1019\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 44s 119ms/step - loss: 2.3210 - accuracy: 0.1037\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 44s 118ms/step - loss: 2.3185 - accuracy: 0.1045\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 44s 118ms/step - loss: 2.3182 - accuracy: 0.1038\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 45s 120ms/step - loss: 2.3150 - accuracy: 0.1066\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 45s 120ms/step - loss: 2.3137 - accuracy: 0.1034\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 44s 118ms/step - loss: 2.3100 - accuracy: 0.1086\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 44s 118ms/step - loss: 2.3068 - accuracy: 0.1116\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 45s 120ms/step - loss: 2.3046 - accuracy: 0.1122\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 45s 120ms/step - loss: 2.2989 - accuracy: 0.1200\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 45s 119ms/step - loss: 2.2916 - accuracy: 0.1269\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 45s 120ms/step - loss: 2.2769 - accuracy: 0.1427\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 45s 119ms/step - loss: 2.2486 - accuracy: 0.1808\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 44s 119ms/step - loss: 2.1716 - accuracy: 0.2674\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 44s 118ms/step - loss: 1.7930 - accuracy: 0.4856\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 46s 122ms/step - loss: 0.8769 - accuracy: 0.7335\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 44s 118ms/step - loss: 0.5307 - accuracy: 0.8339\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 46s 122ms/step - loss: 0.4456 - accuracy: 0.8622\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 46s 123ms/step - loss: 0.4105 - accuracy: 0.8724\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 46s 124ms/step - loss: 0.3853 - accuracy: 0.8825\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 45s 121ms/step - loss: 0.3707 - accuracy: 0.8873\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 45s 120ms/step - loss: 0.3596 - accuracy: 0.8916\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 45s 121ms/step - loss: 0.3522 - accuracy: 0.8937\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 46s 123ms/step - loss: 0.3477 - accuracy: 0.8950\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 46s 122ms/step - loss: 0.3410 - accuracy: 0.8976\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 45s 121ms/step - loss: 0.3362 - accuracy: 0.8989\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 45s 120ms/step - loss: 0.3310 - accuracy: 0.9015\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 46s 122ms/step - loss: 0.3279 - accuracy: 0.9013\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 45s 119ms/step - loss: 0.3265 - accuracy: 0.9022\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 44s 118ms/step - loss: 0.3229 - accuracy: 0.9029\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 45s 119ms/step - loss: 0.3202 - accuracy: 0.9047\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 44s 117ms/step - loss: 0.3166 - accuracy: 0.9067\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 45s 121ms/step - loss: 0.3148 - accuracy: 0.9052\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 45s 121ms/step - loss: 0.3145 - accuracy: 0.9065\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 46s 124ms/step - loss: 0.3121 - accuracy: 0.9064\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 44s 118ms/step - loss: 0.3104 - accuracy: 0.9081\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 44s 118ms/step - loss: 0.3074 - accuracy: 0.9095\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 44s 118ms/step - loss: 0.3062 - accuracy: 0.9085\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 45s 119ms/step - loss: 0.3064 - accuracy: 0.9090\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 45s 119ms/step - loss: 0.3046 - accuracy: 0.9088\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 46s 123ms/step - loss: 0.3034 - accuracy: 0.9104\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 46s 124ms/step - loss: 0.3008 - accuracy: 0.9115\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 46s 123ms/step - loss: 0.2999 - accuracy: 0.9104\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 46s 124ms/step - loss: 0.3004 - accuracy: 0.9107\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 45s 120ms/step - loss: 0.2990 - accuracy: 0.9106\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 45s 120ms/step - loss: 0.2980 - accuracy: 0.9116\n",
      "Epoch 2/5\n",
      " 41/375 [==>...........................] - ETA: 39s - loss: 0.2839 - accuracy: 0.9150"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-54811a178cfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-n 2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'H = model.fit(trainX, trainY,\\n              epochs=n_epochs, batch_size=128)\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2379\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2381\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2382\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1171\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m         \u001b[0mall_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mworst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "H = t2_model.fit(trainX, trainY,\n",
    "              epochs=n_epochs, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "predictions = t2_model.predict(testX, batch_size=128)\n",
    "acc_score = accuracy_score(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1))\n",
    "print(f\"Model Accuracy {acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 Findings\n",
    "\n",
    "1. Model Accuracy is 89.13%\n",
    "2. The average time taken to train the model on a non-gpu PC is - 30s on MNIST data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
